{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "train_data = pd.read_csv('../data/full_size/atec_anti_fraud_train.csv',index_col = 0)\n",
    "testa_data = pd.read_csv('../data/full_size/atec_anti_fraud_test_a.csv',index_col = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_num = int(0.8*train_data.shape[0])\n",
    "test_data = train_data.iloc[train_num:,:]\n",
    "train_data = train_data.iloc[:train_num,:]\n",
    "train_x = train_data.iloc[:,1:]\n",
    "train_y = train_data.iloc[:,0]\n",
    "test_x = test_data.iloc[:,1:]\n",
    "test_y = test_data.iloc[:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from xgboost import XGBClassifier\n",
    "random_clf = RandomForestClassifier(max_depth=9, random_state=0)\n",
    "extra_clf = ExtraTreesClassifier(n_estimators=300)\n",
    "deci_clf = DecisionTreeClassifier(max_depth=10)\n",
    "xgb_clf = XGBClassifier(verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "       colsample_bytree=1, gamma=0, learning_rate=0.1, max_delta_step=0,\n",
       "       max_depth=3, min_child_weight=1, missing=None, n_estimators=100,\n",
       "       n_jobs=1, nthread=None, objective='multi:softprob', random_state=0,\n",
       "       reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=None,\n",
       "       silent=True, subsample=1)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xgb_clf.fit(train_x,train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.01813843, 0.        , 0.        , 0.        , 0.00334129,\n",
       "       0.02052506, 0.04677804, 0.06491647, 0.        , 0.        ,\n",
       "       0.        , 0.00047733, 0.        , 0.        , 0.00906921,\n",
       "       0.01527446, 0.        , 0.0052506 , 0.00906921, 0.00620525,\n",
       "       0.        , 0.        , 0.00572792, 0.00190931, 0.00620525,\n",
       "       0.01050119, 0.00859189, 0.00859189, 0.01384248, 0.01479714,\n",
       "       0.02816229, 0.02768496, 0.01145585, 0.00763723, 0.0052506 ,\n",
       "       0.00763723, 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.00047733, 0.00334129, 0.0052506 , 0.00381862,\n",
       "       0.00668258, 0.00286396, 0.02291169, 0.01431981, 0.00047733,\n",
       "       0.00095465, 0.00047733, 0.        , 0.00572792, 0.        ,\n",
       "       0.        , 0.00143198, 0.00190931, 0.02004773, 0.        ,\n",
       "       0.        , 0.00047733, 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.00047733, 0.00047733,\n",
       "       0.        , 0.        , 0.00047733, 0.00095465, 0.        ,\n",
       "       0.        , 0.01336516, 0.01670644, 0.00334129, 0.00143198,\n",
       "       0.02052506, 0.00286396, 0.        , 0.00095465, 0.00238663,\n",
       "       0.00381862, 0.00190931, 0.        , 0.        , 0.00047733,\n",
       "       0.00334129, 0.00334129, 0.00477327, 0.        , 0.00190931,\n",
       "       0.00190931, 0.00859189, 0.00381862, 0.00429594, 0.00143198,\n",
       "       0.00286396, 0.02243437, 0.        , 0.        , 0.        ,\n",
       "       0.00286396, 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.00047733, 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.00190931, 0.        , 0.00429594,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.00047733,\n",
       "       0.        , 0.        , 0.00047733, 0.00095465, 0.        ,\n",
       "       0.00095465, 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.00047733,\n",
       "       0.        , 0.00047733, 0.        , 0.        , 0.00047733,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.00095465, 0.00286396, 0.        , 0.        , 0.00047733,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.00190931,\n",
       "       0.        , 0.00047733, 0.        , 0.        , 0.        ,\n",
       "       0.00811456, 0.        , 0.        , 0.00095465, 0.        ,\n",
       "       0.        , 0.00047733, 0.00286396, 0.00047733, 0.        ,\n",
       "       0.        , 0.00143198, 0.00095465, 0.0071599 , 0.        ,\n",
       "       0.        , 0.        , 0.00095465, 0.        , 0.00906921,\n",
       "       0.00095465, 0.00190931, 0.        , 0.00143198, 0.0124105 ,\n",
       "       0.1078759 , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.00859189, 0.        , 0.00095465, 0.00859189, 0.        ,\n",
       "       0.        , 0.        , 0.00095465, 0.        , 0.        ,\n",
       "       0.00047733, 0.00047733, 0.        , 0.00047733, 0.        ,\n",
       "       0.        , 0.00047733, 0.        , 0.        , 0.00763723,\n",
       "       0.00190931, 0.00190931, 0.00143198, 0.01575179, 0.        ,\n",
       "       0.00095465, 0.        , 0.00906921, 0.02147971, 0.0052506 ,\n",
       "       0.00047733, 0.        , 0.0052506 , 0.03054893, 0.        ,\n",
       "       0.00143198, 0.        , 0.00286396, 0.0071599 , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.00668258, 0.01909308,\n",
       "       0.02577566, 0.02529833, 0.00190931, 0.00095465, 0.00334129,\n",
       "       0.00095465, 0.00429594, 0.        , 0.        , 0.00047733,\n",
       "       0.01384248, 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.00047733, 0.        ,\n",
       "       0.00095465, 0.        , 0.00095465, 0.00143198, 0.        ,\n",
       "       0.        , 0.        , 0.00047733, 0.        , 0.00095465,\n",
       "       0.        , 0.00047733, 0.00047733, 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.00238663], dtype=float32)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from xgboost import plot_importance\n",
    "xgb_clf.feature_importances_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
