{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Pre definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\python352\\lib\\site-packages\\sklearn\\cross_validation.py:41: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import sklearn\n",
    "from sklearn import svm\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn import preprocessing\n",
    "import lightgbm as lgb\n",
    "from sklearn.model_selection import GridSearchCV,RandomizedSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# divid date\n",
    "import datetime\n",
    "def date2weekday(date):\n",
    "    date = str(date)\n",
    "    year = int(date[0:4])\n",
    "    month = int(date[4:6])\n",
    "    day = int(date[6:])\n",
    "    return datetime.datetime(year,month,day).weekday()\n",
    "\n",
    "def ant_score(truth,score):\n",
    "    FNR1 = 0.001\n",
    "    FNR2 = 0.005\n",
    "    FNR3 = 0.01\n",
    "    min1 = min2 = min3 = 1\n",
    "    for thr in np.arange(0,1+0.001,0.001):\n",
    "        evaluate_table = pd.DataFrame({'truth':truth,'score':score})\n",
    "        evaluate_table.loc[evaluate_table['score']>=thr,'score']=1\n",
    "        evaluate_table.loc[evaluate_table['score']<thr,'score']=0\n",
    "        TP = evaluate_table.loc[(evaluate_table['score']==1)&(evaluate_table['truth']==1)].shape[0]\n",
    "        FN = evaluate_table.loc[(evaluate_table['score']==0)&(evaluate_table['truth']==1)].shape[0]\n",
    "        TN = evaluate_table.loc[(evaluate_table['score']==0)&(evaluate_table['truth']==0)].shape[0]\n",
    "        FP = evaluate_table.loc[(evaluate_table['score']==1)&(evaluate_table['truth']==0)].shape[0]\n",
    "        TPR = TP/(TP+FN)\n",
    "        FNR = FP/(TN+FP)\n",
    "        if abs(FNR-FNR1)<min1:\n",
    "            min1 = abs(FNR-FNR1)\n",
    "            FNR11 = FNR\n",
    "            TPR1 = TPR\n",
    "        if abs(FNR-FNR2)<min2:\n",
    "            min2 = abs(FNR-FNR2)\n",
    "            FNR22 = FNR\n",
    "            TPR2 = TPR\n",
    "        if abs(FNR-FNR3)<min3:\n",
    "            min3 = abs(FNR-FNR3)\n",
    "            FNR33 = FNR\n",
    "            TPR3 = TPR\n",
    "    return 0.4*TPR1+0.3*TPR2+0.3*TPR3\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "from sklearn import metrics\n",
    "import bisect\n",
    "\n",
    "\n",
    "def get_tpr_from_fpr(fpr_array, tpr_array, target):\n",
    "    fpr_index = np.where(fpr_array == target)\n",
    "    assert target <= 0.01, 'the value of fpr in the custom metric function need lt 0.01'\n",
    "    if len(fpr_index[0]) > 0:\n",
    "        return np.mean(tpr_array[fpr_index])\n",
    "    else:\n",
    "        tmp_index = bisect.bisect(fpr_array, target)\n",
    "        fpr_tmp_1 = fpr_array[tmp_index-1]\n",
    "        fpr_tmp_2 = fpr_array[tmp_index]\n",
    "        if (target - fpr_tmp_1) > (fpr_tmp_2 - target):\n",
    "            tpr_index = tmp_index\n",
    "        else:\n",
    "            tpr_index = tmp_index - 1\n",
    "        return tpr_array[tpr_index]\n",
    "\n",
    "\n",
    "def eval_metric(labels,pred):\n",
    "    fpr, tpr, _ = metrics.roc_curve(labels, pred, pos_label=1)\n",
    "    tpr1 = get_tpr_from_fpr(fpr, tpr, 0.001)\n",
    "    tpr2 = get_tpr_from_fpr(fpr, tpr, 0.005)\n",
    "    tpr3 = get_tpr_from_fpr(fpr, tpr, 0.01)\n",
    "    return 0.4*tpr1 + 0.3*tpr2 + 0.3*tpr3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. data preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1 read train and test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# constant definition\n",
    "# small_data_path = './data/small_size/sample_atec_anti_fraud_train.csv'\n",
    "train_path = '../data/full_size/atec_anti_fraud_train.csv'\n",
    "testb_path='../data/full_size/atec_anti_fraud_test_b.csv'\n",
    "train_data = pd.read_csv(train_path,index_col = 0)\n",
    "testb_data = pd.read_csv('../data/full_size/atec_anti_fraud_test_b.csv',index_col = 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2 feature selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# find no missing value features\n",
    "no_nan_features = ['date']\n",
    "i = 1\n",
    "while i<len(testb_data.columns):\n",
    "    name = testb_data.columns[i]\n",
    "    if train_data[name].isnull().sum()==0:\n",
    "        no_nan_features.append(name)\n",
    "    i+=1\n",
    "    \n",
    "# find small missing features\n",
    "small_missing_features=[]\n",
    "i = 1\n",
    "while i<len(testb_data.columns):\n",
    "    name = testb_data.columns[i]\n",
    "    train_missing_rate = train_data[name].isnull().sum()/train_data.shape[0]\n",
    "    test_missing_rate = testb_data[name].isnull().sum()/testb_data.shape[0]\n",
    "    if 0<train_missing_rate<0.3 and abs(test_missing_rate-train_missing_rate)<0.1:\n",
    "        small_missing_features.append(name)\n",
    "    i+=1\n",
    "    \n",
    "filldable_features = small_missing_features+no_nan_features\n",
    "# feature selection\n",
    "feature_score_files=['xgb_feature_scores.csv','lgb_feature_scores2.csv']\n",
    "common_important_features=set()\n",
    "all_important_features=set()\n",
    "top=100\n",
    "for file in feature_score_files:\n",
    "    features = set(pd.read_csv(file,index_col = 0,header=None).sort_values(by=1,ascending=False).iloc[:top,0].index.tolist())\n",
    "    all_important_features = all_important_features|features\n",
    "    if common_important_features:\n",
    "        common_important_features = common_important_features&features\n",
    "    else:\n",
    "        common_important_features=features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.3 fill missing values for fiildable columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data[filldable_features] = train_data[filldable_features].fillna(train_data[filldable_features].mean())\n",
    "testb_data[filldable_features] = testb_data[filldable_features].fillna(testb_data[filldable_features].mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.4 eliminate unlabeled data/convert -1 to 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert -1 to 1\n",
    "train_data['label'] = train_data['label'].apply(lambda x: 1 if x==-1 else x)\n",
    "train_data = train_data.sort_values(by=['date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import SMOTE,ADASYN\n",
    "def random_subsample(data,target_ratio):\n",
    "    pos_data = data[data['label']==0]\n",
    "    neg_data = data[data['label']==1]\n",
    "    target_pos_num = int(neg_data.shape[0]/target_ratio)\n",
    "    pos_data = data.iloc[np.random.randint(pos_data.shape[0],size=target_pos_num),:]\n",
    "    return pd.concat([pos_data,neg_data])\n",
    "    \n",
    "def random_oversample(data,target_ratio):\n",
    "    pos_data = data[data['label']==0]\n",
    "    neg_data = data[data['label']==1]\n",
    "    target_new_neg_num = int(pos_data.shape[0]*target_ratio)-neg_data.shape[0]\n",
    "    new_neg_data = neg_data.iloc[np.random.randint(neg_data.shape[0],size=target_new_neg_num),:]\n",
    "    neg_data = pd.concat([neg_data,new_neg_data])\n",
    "    \n",
    "    return pd.concat([pos_data,neg_data])\n",
    "    \n",
    "def mySMOTE(data):\n",
    "    X = data.drop(columns=['label'])\n",
    "    Y = data.label\n",
    "    resampled_x,resampled_y = SMOTE().fit_sample(X,Y)\n",
    "    resampled_data = resasmpled_x.copy()\n",
    "    resampled_data['label'] = resampled_y\n",
    "    return resampled_data\n",
    "    \n",
    "def myADASYN(data):\n",
    "    X = data.drop(columns=['label'])\n",
    "    Y = data.label\n",
    "    resampled_x,resampled_y = ADASYN().fit_sample(X,Y)\n",
    "    resampled_data = resasmpled_x.copy()\n",
    "    resampled_data['label'] = resampled_y\n",
    "    return resampled_data\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.6 train test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # strategy 1: only filldable\n",
    "# train_data = train_data[['label']+filldable_features]\n",
    "\n",
    "# stragey 2: filldable | common_important:158\n",
    "selected_features = list(set(filldable_features)|common_important_features)\n",
    "selected_features = testb_data.columns.tolist()\n",
    "train_data = train_data[['label']+selected_features]\n",
    "\n",
    "# # strategy 3: filldable|all_important\n",
    "# selected_features = list(set(filldable_features)|all_important_features)\n",
    "# train_data = train_data[['label']+selected_features]\n",
    "\n",
    "\n",
    "train_num = int(0.8*train_data.shape[0])\n",
    "test_data = train_data.iloc[train_num:,:]\n",
    "cut_train_data = train_data.iloc[:train_num,:]\n",
    "sampled_train_data = cut_train_data.copy()\n",
    "# sampled_train_data = random_oversample(sampled_train_data,0.05)\n",
    "train_x = sampled_train_data.drop(columns=['label'])\n",
    "train_y = sampled_train_data['label']\n",
    "test_x = test_data.drop(columns=['label'])\n",
    "test_y = test_data['label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "298"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(selected_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Build LightGMB model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.1 Grid Search for best parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param = {'max_depth':[3,5,7,9],'num_leaves':[6,25,85,350], 'num_trees':[100,300,500,700,900]}\n",
    "lgb_clf = lgb.LGBMClassifier(boosting_type= 'gbdt', objective='binary',colsample_bytree=0.8,\n",
    "                   subsample= 0.8)\n",
    "lgb_random_cv = RandomizedSearchCV(lgb_clf,param,verbose=True,scoring='precision')\n",
    "lgb_random_cv.fit(train_x,train_y,eval_metric='error',eval_set=[(test_x, test_y)],early_stopping_rounds=20)\n",
    "lgb_random_cv.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.2 train lightgbm based on best parameters with cross validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "def kfold_by_date(data,k=5):\n",
    "    kf = KFold(n_splits=k,random_state=0,shuffle=True)\n",
    "    dates = np.array(data['date'].value_counts().index.tolist())\n",
    "    for train_index,test_index in kf.split(dates):\n",
    "        train_data = data[data['date'].isin(dates[train_index])]\n",
    "        valid_data = data[data['date'].isin(dates[test_index])]\n",
    "        yield train_data,valid_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2.1 normal k-fold cross validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fitting model1...\n"
     ]
    },
    {
     "ename": "MemoryError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mMemoryError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-18-a8251d117b82>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     19\u001b[0m     \u001b[1;31m# training\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     20\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'fitting model{}...'\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 21\u001b[1;33m     \u001b[0mlgb_300n350le9d01l\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msub_train_x\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0msub_train_y\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0meval_metric\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'error'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0meval_set\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtest_x\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest_y\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mearly_stopping_rounds\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m100\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     22\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'model{} predicting...'\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     23\u001b[0m     \u001b[0msub_predict_y\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlgb_300n350le9d01l\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msub_test_x\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32me:\\python352\\lib\\site-packages\\lightgbm\\sklearn.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, sample_weight, init_score, eval_set, eval_names, eval_sample_weight, eval_class_weight, eval_init_score, eval_metric, early_stopping_rounds, verbose, feature_name, categorical_feature, callbacks)\u001b[0m\n\u001b[0;32m    673\u001b[0m                                         \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeature_name\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfeature_name\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    674\u001b[0m                                         \u001b[0mcategorical_feature\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcategorical_feature\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 675\u001b[1;33m                                         callbacks=callbacks)\n\u001b[0m\u001b[0;32m    676\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    677\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32me:\\python352\\lib\\site-packages\\lightgbm\\sklearn.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, sample_weight, init_score, group, eval_set, eval_names, eval_sample_weight, eval_class_weight, eval_init_score, eval_group, eval_metric, early_stopping_rounds, verbose, feature_name, categorical_feature, callbacks)\u001b[0m\n\u001b[0;32m    467\u001b[0m                               \u001b[0mverbose_eval\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeature_name\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfeature_name\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    468\u001b[0m                               \u001b[0mcategorical_feature\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcategorical_feature\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 469\u001b[1;33m                               callbacks=callbacks)\n\u001b[0m\u001b[0;32m    470\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    471\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mevals_result\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32me:\\python352\\lib\\site-packages\\lightgbm\\engine.py\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(params, train_set, num_boost_round, valid_sets, valid_names, fobj, feval, init_model, feature_name, categorical_feature, early_stopping_rounds, evals_result, verbose_eval, learning_rates, keep_training_booster, callbacks)\u001b[0m\n\u001b[0;32m    178\u001b[0m     \u001b[1;31m# construct booster\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    179\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 180\u001b[1;33m         \u001b[0mbooster\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mBooster\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mparams\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_set\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtrain_set\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    181\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mis_valid_contain_train\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    182\u001b[0m             \u001b[0mbooster\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mset_train_data_name\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_data_name\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32me:\\python352\\lib\\site-packages\\lightgbm\\basic.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, params, train_set, model_file, silent)\u001b[0m\n\u001b[0;32m   1301\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhandle\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mctypes\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mc_void_p\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1302\u001b[0m             _safe_call(_LIB.LGBM_BoosterCreate(\n\u001b[1;32m-> 1303\u001b[1;33m                 \u001b[0mtrain_set\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconstruct\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1304\u001b[0m                 \u001b[0mc_str\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mparams_str\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1305\u001b[0m                 ctypes.byref(self.handle)))\n",
      "\u001b[1;32me:\\python352\\lib\\site-packages\\lightgbm\\basic.py\u001b[0m in \u001b[0;36mconstruct\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    854\u001b[0m                                 \u001b[0mweight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgroup\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgroup\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minit_score\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minit_score\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    855\u001b[0m                                 \u001b[0mpredictor\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_predictor\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msilent\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msilent\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeature_name\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfeature_name\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 856\u001b[1;33m                                 categorical_feature=self.categorical_feature, params=self.params)\n\u001b[0m\u001b[0;32m    857\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfree_raw_data\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    858\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32me:\\python352\\lib\\site-packages\\lightgbm\\basic.py\u001b[0m in \u001b[0;36m_lazy_init\u001b[1;34m(self, data, label, reference, weight, group, init_score, predictor, silent, feature_name, categorical_feature, params)\u001b[0m\n\u001b[0;32m    646\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpandas_categorical\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mreference\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpandas_categorical\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    647\u001b[0m             \u001b[0mcategorical_feature\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mreference\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcategorical_feature\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 648\u001b[1;33m         \u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeature_name\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcategorical_feature\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpandas_categorical\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_data_from_pandas\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeature_name\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcategorical_feature\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpandas_categorical\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    649\u001b[0m         \u001b[0mlabel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_label_from_pandas\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlabel\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    650\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata_has_header\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32me:\\python352\\lib\\site-packages\\lightgbm\\basic.py\u001b[0m in \u001b[0;36m_data_from_pandas\u001b[1;34m(data, feature_name, categorical_feature, pandas_categorical)\u001b[0m\n\u001b[0;32m    240\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mDataFrame\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    241\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mfeature_name\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'auto'\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mfeature_name\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 242\u001b[1;33m             \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrename\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    243\u001b[0m         \u001b[0mcat_cols\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mselect_dtypes\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minclude\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'category'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    244\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mpandas_categorical\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# train dataset\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python35\\site-packages\\pandas\\util\\_decorators.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    185\u001b[0m         \u001b[1;33m@\u001b[0m\u001b[0mwraps\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    186\u001b[0m         \u001b[1;32mdef\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 187\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    188\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    189\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mPY2\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python35\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36mrename\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   3779\u001b[0m         \u001b[0mkwargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'axis'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3780\u001b[0m         \u001b[0mkwargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'mapper'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3781\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrename\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3782\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3783\u001b[0m     \u001b[1;33m@\u001b[0m\u001b[0mSubstitution\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0m_shared_doc_kwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python35\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36mrename\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    958\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    959\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_consolidate_inplace\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 960\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0minplace\u001b[0m \u001b[1;32melse\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdeep\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    961\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    962\u001b[0m         \u001b[1;31m# start in the axis order to eliminate too many copies\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python35\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36mcopy\u001b[1;34m(self, deep)\u001b[0m\n\u001b[0;32m   5108\u001b[0m         \u001b[0mdtype\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mobject\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   5109\u001b[0m         \"\"\"\n\u001b[1;32m-> 5110\u001b[1;33m         \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_data\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdeep\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdeep\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   5111\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_constructor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__finalize__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   5112\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python35\\site-packages\\pandas\\core\\internals.py\u001b[0m in \u001b[0;36mcopy\u001b[1;34m(self, deep, mgr)\u001b[0m\n\u001b[0;32m   3918\u001b[0m             \u001b[0mnew_axes\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0maxes\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3919\u001b[0m         return self.apply('copy', axes=new_axes, deep=deep,\n\u001b[1;32m-> 3920\u001b[1;33m                           do_integrity_check=False)\n\u001b[0m\u001b[0;32m   3921\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3922\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mas_array\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtranspose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mitems\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python35\\site-packages\\pandas\\core\\internals.py\u001b[0m in \u001b[0;36mapply\u001b[1;34m(self, f, axes, filter, do_integrity_check, consolidate, **kwargs)\u001b[0m\n\u001b[0;32m   3579\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3580\u001b[0m             \u001b[0mkwargs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'mgr'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3581\u001b[1;33m             \u001b[0mapplied\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mb\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3582\u001b[0m             \u001b[0mresult_blocks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_extend_blocks\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mapplied\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresult_blocks\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3583\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python35\\site-packages\\pandas\\core\\internals.py\u001b[0m in \u001b[0;36mcopy\u001b[1;34m(self, deep, mgr)\u001b[0m\n\u001b[0;32m    776\u001b[0m         \u001b[0mvalues\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    777\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mdeep\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 778\u001b[1;33m             \u001b[0mvalues\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mvalues\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    779\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmake_block_same_class\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    780\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mMemoryError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# train best parameter lgb_random_cv\n",
    "neg_num = sampled_train_data.label.value_counts()[0]\n",
    "pos_num = sampled_train_data.label.value_counts()[0]\n",
    "lgb_300n350le9d01l = lgb.LGBMClassifier(boosting_type= 'dart', objective='binary',colsample_bytree=0.6,\n",
    "                   subsample= 0.6,max_depth=9,num_leaves=400,n_estimators=200,random_state = 0,scale_pos_weight=neg_num/pos_num)\n",
    "\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn import metrics\n",
    "kf = KFold(n_splits=5,random_state=0,shuffle=True)\n",
    "lgb_300n350le9d01l_list = []\n",
    "predict_probas = []\n",
    "i=1\n",
    "for train_index,test_index in kf.split(sampled_train_data):\n",
    "    sub_train_x = train_x.iloc[train_index]\n",
    "    sub_train_y = train_y.iloc[train_index]\n",
    "    sub_test_x = train_x.iloc[test_index]\n",
    "    sub_test_y = train_y.iloc[test_index]\n",
    "    \n",
    "    # training\n",
    "    print('fitting model{}...'.format(i))\n",
    "    lgb_300n350le9d01l.fit(sub_train_x,sub_train_y,eval_metric='error',eval_set=[(test_x, test_y)],early_stopping_rounds=100)\n",
    "    print('model{} predicting...'.format(i))\n",
    "    sub_predict_y = lgb_300n350le9d01l.predict(sub_test_x)\n",
    "    sub_predict_y_proba = lgb_300n350le9d01l.predict_proba(sub_test_x)[:,1]\n",
    "    print('sub scoring...')\n",
    "    print('precision: {},recall:{},ant_score:{}'.format(metrics.precision_score(sub_test_y,sub_predict_y),\n",
    "                                                           metrics.recall_score(sub_test_y,sub_predict_y),\n",
    "                                                           eval_metric(sub_test_y,sub_predict_y)))\n",
    "    print('out scoring...')\n",
    "    predict_y = lgb_300n350le9d01l.predict(test_x)\n",
    "    predict_y_proba = lgb_300n350le9d01l.predict_proba(test_x)[:,1]\n",
    "    print('precision: {}, recall: {}, ant_score: {}'.format(metrics.precision_score(test_y,predict_y),\n",
    "                                                       metrics.recall_score(test_y,predict_y),\n",
    "                                                       eval_metric(test_y,predict_y)))\n",
    "    predict_probas.append(predict_y_proba)\n",
    "    lgb_300n350le9d01l_list.append(lgb_300n350le9d01l)\n",
    "    i+=1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2.2 date-based kfold-validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'kfold_by_date' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-14-78d061231035>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[0mpredict_probas\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 12\u001b[1;33m \u001b[1;32mfor\u001b[0m \u001b[0msub_train_data\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0msub_test_data\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mkfold_by_date\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msampled_train_data\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     13\u001b[0m     \u001b[0msub_train_x\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msub_train_data\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'label'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m     \u001b[0msub_train_y\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msub_train_data\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'label'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'kfold_by_date' is not defined"
     ]
    }
   ],
   "source": [
    "# train best parameter lgb_random_cv\n",
    "\n",
    "lgb_300n350le9d01l = lgb.LGBMClassifier(boosting_type= 'dart', objective='binary',colsample_bytree=0.8,\n",
    "                   subsample= 0.8,max_depth=10,num_leaves=800,n_estimators=100)\n",
    "\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn import metrics\n",
    "kf = KFold(n_splits=5,random_state=0,shuffle=True)\n",
    "lgb_300n350le9d01l_list = []\n",
    "predict_probas = []\n",
    "i=1\n",
    "for sub_train_data,sub_test_data in kfold_by_date(sampled_train_data,k=5):\n",
    "    sub_train_x = sub_train_data.drop(columns=['label'])\n",
    "    sub_train_y = sub_train_data['label']\n",
    "    sub_test_x = sub_test_data.drop(columns=['label'])\n",
    "    sub_test_y = sub_test_data['label']\n",
    "    # training\n",
    "    print('fitting model{}...'.format(i))\n",
    "    lgb_300n350le9d01l.fit(sub_train_x,sub_train_y,eval_metric='error',eval_set=[(test_x, test_y)],early_stopping_rounds=50)\n",
    "    print('model{} predicting...'.format(i))\n",
    "    sub_predict_y = lgb_300n350le9d01l.predict(sub_test_x)\n",
    "    sub_predict_y_proba = lgb_300n350le9d01l.predict_proba(sub_test_x)[:,1]\n",
    "    print('sub scoring...')\n",
    "    print('precision: {},recall:{},ant_score:{}'.format(metrics.precision_score(sub_test_y,sub_predict_y),\n",
    "                                                           metrics.recall_score(sub_test_y,sub_predict_y),\n",
    "                                                           eval_metric(sub_test_y,sub_predict_y)))\n",
    "    print('out scoring...')\n",
    "    predict_y = lgb_300n350le9d01l.predict(test_x)\n",
    "    predict_y_proba = lgb_300n350le9d01l.predict_proba(test_x)[:,1]\n",
    "    print('precision: {}, recall: {}, ant_score: {}'.format(metrics.precision_score(test_y,predict_y),\n",
    "                                                       metrics.recall_score(test_y,predict_y),\n",
    "                                                       eval_metric(test_y,predict_y)))\n",
    "    predict_probas.append(predict_y_proba)\n",
    "    lgb_300n350le9d01l_list.append(lgb_300n350le9d01l)\n",
    "    i+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LGBMClassifier(boosting_type='dart', class_weight=None, colsample_bytree=0.8,\n",
       "        learning_rate=0.1, max_depth=9, min_child_samples=20,\n",
       "        min_child_weight=0.001, min_split_gain=0.0, n_estimators=500,\n",
       "        n_jobs=-1, num_leaves=400, objective='binary', random_state=0,\n",
       "        reg_alpha=0.0, reg_lambda=0.0, scale_pos_weight=1.0, silent=True,\n",
       "        subsample=0.8, subsample_for_bin=200000, subsample_freq=1)"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lgb_300n350le9d01l"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.3 evaluation on test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ant_score:0.4299147810755216\n"
     ]
    }
   ],
   "source": [
    "predict_probas = pd.DataFrame(predict_probas).T\n",
    "predict_scores = predict_probas.mean(axis = 1).values\n",
    "print('ant_score:{}'.format(eval_metric(test_y,predict_scores)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train_x.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.4 prediction on testb set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predicting on final outer testset.....\n"
     ]
    }
   ],
   "source": [
    "# # predict on testb\n",
    "testb_data = pd.read_csv('../data/full_size/atec_anti_fraud_test_b.csv',index_col = 0)\n",
    "\n",
    "# predict\n",
    "testb_data[filldable_features] = testb_data[filldable_features].fillna(testb_data[filldable_features].mean())\n",
    "testb_data = testb_data[selected_features]\n",
    "# testb_data['date'] = testb_data['date'].apply(lambda x:int(str(x)[6:]))\n",
    "print('predicting on final outer testset.....')\n",
    "scores = [] # store score predicted by every cv model\n",
    "for model in lgb_300n350le9d01l_list:\n",
    "    score = model.predict_proba(testb_data)[:,1]\n",
    "    scores.append(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0414024258599 0.0730199802571\n"
     ]
    }
   ],
   "source": [
    "final_scores = pd.DataFrame(scores).T.mean(axis=1).values\n",
    "print(final_scores.mean(),final_scores.std())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "writing result to file...\n"
     ]
    }
   ],
   "source": [
    "print('writing result to file...')\n",
    "final_result = pd.DataFrame({'score':final_scores},index=testb_data.index)\n",
    "final_result.to_csv('../submission/testb_lgb_500n400le9d01l_fillnan_sf158_normalcv5_original_date_scale_pos_weight.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
