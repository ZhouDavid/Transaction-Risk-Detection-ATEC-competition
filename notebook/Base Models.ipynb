{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Prepare data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1 Read Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import sklearn\n",
    "from sklearn import svm\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn import preprocessing\n",
    "import lightgbm as lgb\n",
    "from sklearn.model_selection import GridSearchCV,RandomizedSearchCV\n",
    "\n",
    "# constant definition\n",
    "# small_data_path = './data/small_size/sample_atec_anti_fraud_train.csv'\n",
    "train_path = '../data/full_size/atec_anti_fraud_train.csv'\n",
    "testb_path='../data/full_size/atec_anti_fraud_test_b.csv'\n",
    "train_data = pd.read_csv(train_path,index_col = 0)\n",
    "testb_data = pd.read_csv(testb_path,index_col = 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2 Feature Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# find no missing value features\n",
    "no_nan_features = ['date']\n",
    "i = 1\n",
    "while i<len(testb_data.columns):\n",
    "    name = testb_data.columns[i]\n",
    "    if train_data[name].isnull().sum()==0:\n",
    "        no_nan_features.append(name)\n",
    "    i+=1\n",
    "    \n",
    "# find small missing features\n",
    "small_missing_features=[]\n",
    "i = 1\n",
    "while i<len(testb_data.columns):\n",
    "    name = testb_data.columns[i]\n",
    "    train_missing_rate = train_data[name].isnull().sum()/train_data.shape[0]\n",
    "    test_missing_rate = testb_data[name].isnull().sum()/testb_data.shape[0]\n",
    "    if 0<train_missing_rate<0.3 and abs(test_missing_rate-train_missing_rate)<0.1:\n",
    "        small_missing_features.append(name)\n",
    "    i+=1\n",
    "    \n",
    "filldable_features = small_missing_features+no_nan_features\n",
    "# feature selection\n",
    "feature_score_files=['xgb_feature_scores.csv','lgb_feature_scores2.csv']\n",
    "common_important_features=set()\n",
    "all_important_features=set()\n",
    "top=100\n",
    "for file in feature_score_files:\n",
    "    features = set(pd.read_csv(file,index_col = 0,header=None).sort_values(by=1,ascending=False).iloc[:top,0].index.tolist())\n",
    "    all_important_features = all_important_features|features\n",
    "    if common_important_features:\n",
    "        common_important_features = common_important_features&features\n",
    "    else:\n",
    "        common_important_features=features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_features = filldable_features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.3 Fill selected features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data[filldable_features] = train_data[filldable_features].fillna(train_data[filldable_features].mean())\n",
    "testb_data[filldable_features] = testb_data[filldable_features].fillna(testb_data[filldable_features].mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.4 train test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# preprocess sample data\n",
    "train_data = train_data[['label']+selected_features]\n",
    "train_data = train_data[train_data['label']!=-1] # delete all -1 labeled data\n",
    "train_data = train_data.sort_values(by=['date'])\n",
    "\n",
    "train_num = int(0.8*train_data.shape[0])\n",
    "test_data = train_data.iloc[train_num:,:]\n",
    "train_data = train_data.iloc[:train_num,:]\n",
    "train_x = train_data.drop(columns=['label'])\n",
    "train_y = train_data['label']\n",
    "test_x = test_data.drop(columns=['label'])\n",
    "test_y = test_data['label']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Build base models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1 Build Bayessian Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BernoulliNB(alpha=1.0, binarize=0.0, class_prior=None, fit_prior=True)"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "multinomial_nb_clf = BernoulliNB()\n",
    "multinomial_nb_clf.fit(train_x,train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0721766772628409 0.8201520912547529\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import precision_score,recall_score\n",
    "predict_y = multinomial_nb_clf.predict(test_x)\n",
    "predict_y_proba = multinomial_nb_clf.predict_proba(test_x)[:,1]\n",
    "print(precision_score(test_y,predict_y),recall_score(test_y,predict_y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2 Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=9, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=100, n_jobs=1,\n",
       "            oob_score=False, random_state=0, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "rf_clf = RandomForestClassifier(n_estimators=100,max_depth=9, random_state=0)\n",
    "rf_clf.fit(train_x,train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.3166877370417193"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict_y=rf_clf.predict(test_x)\n",
    "from sklearn.metrics import precision_score,recall_score\n",
    "recall_score(train_y,predict_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Model evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.1 Evaluation function definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ant_score(truth,score):\n",
    "    FNR1 = 0.001\n",
    "    FNR2 = 0.005\n",
    "    FNR3 = 0.01\n",
    "    min1 = min2 = min3 = 1\n",
    "    for thr in np.arange(0,1+0.001,0.001):\n",
    "        evaluate_table = pd.DataFrame({'truth':truth,'score':score})\n",
    "        evaluate_table.loc[evaluate_table['score']>=thr,'score']=1\n",
    "        evaluate_table.loc[evaluate_table['score']<thr,'score']=0\n",
    "        TP = evaluate_table.loc[(evaluate_table['score']==1)&(evaluate_table['truth']==1)].shape[0]\n",
    "        FN = evaluate_table.loc[(evaluate_table['score']==0)&(evaluate_table['truth']==1)].shape[0]\n",
    "        TN = evaluate_table.loc[(evaluate_table['score']==0)&(evaluate_table['truth']==0)].shape[0]\n",
    "        FP = evaluate_table.loc[(evaluate_table['score']==1)&(evaluate_table['truth']==0)].shape[0]\n",
    "        TPR = TP/(TP+FN)\n",
    "        FNR = FP/(TN+FP)\n",
    "        if abs(FNR-FNR1)<min1:\n",
    "            min1 = abs(FNR-FNR1)\n",
    "            FNR11 = FNR\n",
    "            TPR1 = TPR\n",
    "        if abs(FNR-FNR2)<min2:\n",
    "            min2 = abs(FNR-FNR2)\n",
    "            FNR22 = FNR\n",
    "            TPR2 = TPR\n",
    "        if abs(FNR-FNR3)<min3:\n",
    "            min3 = abs(FNR-FNR3)\n",
    "            FNR33 = FNR\n",
    "            TPR3 = TPR\n",
    "    return 0.4*TPR1+0.3*TPR2+0.3*TPR3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.2 Define predict function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mannual_predict_proba():\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
