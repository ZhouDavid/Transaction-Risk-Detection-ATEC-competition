{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\python352\\lib\\site-packages\\sklearn\\cross_validation.py:41: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn import preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reading data...\n",
      "scaling...\n"
     ]
    }
   ],
   "source": [
    "# data preprocessing\n",
    "print('reading data...')\n",
    "df = pd.read_csv('./data/full_size/atec_anti_fraud_train.csv',index_col = 0) # read large data\n",
    "df = df[df['label']!=-1]\n",
    "df = df.fillna(df.mode().iloc[0]) # fill nan with most common value\n",
    "\n",
    "X = df.iloc[:,2:] # feature without time\n",
    "Y = df.iloc[:,0] # label\n",
    "x_train,x_test,y_train,y_test=train_test_split(X,Y,test_size=0.2,random_state=1) # split train and test set\n",
    "print('scaling...')\n",
    "scaler = preprocessing.StandardScaler() # scale\n",
    "x_train = pd.DataFrame(scaler.fit_transform(x_train),index = x_train.index,columns = x_train.columns)\n",
    "x_test = pd.DataFrame(scaler.fit_transform(x_test),index = x_test.index,columns = x_test.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-- Epoch 1\n",
      "Norm: 330.63, NNZs: 297, Bias: -876.087882, T: 792004, Avg. loss: 51.196213\n",
      "Total training time: 0.87 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 282.13, NNZs: 297, Bias: -718.420050, T: 1584008, Avg. loss: 9.583106\n",
      "Total training time: 1.80 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 253.66, NNZs: 297, Bias: -630.274142, T: 2376012, Avg. loss: 7.446409\n",
      "Total training time: 2.73 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 238.17, NNZs: 297, Bias: -568.298484, T: 3168016, Avg. loss: 6.363877\n",
      "Total training time: 3.73 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 222.13, NNZs: 297, Bias: -523.293127, T: 3960020, Avg. loss: 5.623774\n",
      "Total training time: 4.68 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 209.87, NNZs: 297, Bias: -487.184289, T: 4752024, Avg. loss: 5.179053\n",
      "Total training time: 5.59 seconds.\n",
      "-- Epoch 7\n",
      "Norm: 202.01, NNZs: 297, Bias: -456.251999, T: 5544028, Avg. loss: 4.716958\n",
      "Total training time: 6.54 seconds.\n",
      "-- Epoch 8\n",
      "Norm: 193.11, NNZs: 297, Bias: -430.874421, T: 6336032, Avg. loss: 4.443011\n",
      "Total training time: 7.48 seconds.\n",
      "-- Epoch 9\n",
      "Norm: 184.69, NNZs: 297, Bias: -409.132851, T: 7128036, Avg. loss: 4.158011\n",
      "Total training time: 8.41 seconds.\n",
      "-- Epoch 10\n",
      "Norm: 177.66, NNZs: 297, Bias: -389.853129, T: 7920040, Avg. loss: 3.925215\n",
      "Total training time: 9.29 seconds.\n",
      "-- Epoch 11\n",
      "Norm: 172.33, NNZs: 297, Bias: -372.259760, T: 8712044, Avg. loss: 3.615450\n",
      "Total training time: 10.17 seconds.\n",
      "-- Epoch 12\n",
      "Norm: 167.18, NNZs: 297, Bias: -356.482651, T: 9504048, Avg. loss: 3.465012\n",
      "Total training time: 11.04 seconds.\n",
      "-- Epoch 13\n",
      "Norm: 161.85, NNZs: 297, Bias: -342.507241, T: 10296052, Avg. loss: 3.290762\n",
      "Total training time: 11.90 seconds.\n",
      "-- Epoch 14\n",
      "Norm: 157.44, NNZs: 297, Bias: -329.468951, T: 11088056, Avg. loss: 3.128561\n",
      "Total training time: 12.77 seconds.\n",
      "-- Epoch 15\n",
      "Norm: 153.25, NNZs: 297, Bias: -317.515257, T: 11880060, Avg. loss: 3.001142\n",
      "Total training time: 13.64 seconds.\n",
      "-- Epoch 16\n",
      "Norm: 149.52, NNZs: 297, Bias: -306.387523, T: 12672064, Avg. loss: 2.882105\n",
      "Total training time: 14.51 seconds.\n",
      "-- Epoch 17\n",
      "Norm: 145.57, NNZs: 297, Bias: -296.248621, T: 13464068, Avg. loss: 2.788131\n",
      "Total training time: 15.37 seconds.\n",
      "-- Epoch 18\n",
      "Norm: 142.77, NNZs: 297, Bias: -286.363072, T: 14256072, Avg. loss: 2.683849\n",
      "Total training time: 16.23 seconds.\n",
      "-- Epoch 19\n",
      "Norm: 138.99, NNZs: 297, Bias: -277.639836, T: 15048076, Avg. loss: 2.592741\n",
      "Total training time: 17.08 seconds.\n",
      "-- Epoch 20\n",
      "Norm: 135.71, NNZs: 297, Bias: -269.341040, T: 15840080, Avg. loss: 2.465495\n",
      "Total training time: 17.91 seconds.\n",
      "-- Epoch 21\n",
      "Norm: 133.56, NNZs: 297, Bias: -261.019115, T: 16632084, Avg. loss: 2.371407\n",
      "Total training time: 18.76 seconds.\n",
      "-- Epoch 22\n",
      "Norm: 130.66, NNZs: 297, Bias: -253.601166, T: 17424088, Avg. loss: 2.324684\n",
      "Total training time: 19.62 seconds.\n",
      "-- Epoch 23\n",
      "Norm: 128.31, NNZs: 297, Bias: -246.363688, T: 18216092, Avg. loss: 2.272934\n",
      "Total training time: 20.45 seconds.\n",
      "-- Epoch 24\n",
      "Norm: 125.24, NNZs: 297, Bias: -239.914450, T: 19008096, Avg. loss: 2.197698\n",
      "Total training time: 21.28 seconds.\n",
      "-- Epoch 25\n",
      "Norm: 123.01, NNZs: 297, Bias: -233.424952, T: 19800100, Avg. loss: 2.110647\n",
      "Total training time: 22.12 seconds.\n",
      "-- Epoch 26\n",
      "Norm: 120.73, NNZs: 297, Bias: -227.310904, T: 20592104, Avg. loss: 2.030792\n",
      "Total training time: 22.97 seconds.\n",
      "-- Epoch 27\n",
      "Norm: 118.71, NNZs: 297, Bias: -221.391512, T: 21384108, Avg. loss: 1.971879\n",
      "Total training time: 23.78 seconds.\n",
      "-- Epoch 28\n",
      "Norm: 116.61, NNZs: 297, Bias: -215.800455, T: 22176112, Avg. loss: 1.936967\n",
      "Total training time: 24.60 seconds.\n",
      "-- Epoch 29\n",
      "Norm: 114.62, NNZs: 297, Bias: -210.451574, T: 22968116, Avg. loss: 1.854961\n",
      "Total training time: 25.41 seconds.\n",
      "-- Epoch 30\n",
      "Norm: 112.30, NNZs: 297, Bias: -205.521504, T: 23760120, Avg. loss: 1.848273\n",
      "Total training time: 26.23 seconds.\n",
      "-- Epoch 31\n",
      "Norm: 110.74, NNZs: 297, Bias: -200.420975, T: 24552124, Avg. loss: 1.774512\n",
      "Total training time: 27.06 seconds.\n",
      "-- Epoch 32\n",
      "Norm: 108.90, NNZs: 297, Bias: -195.708887, T: 25344128, Avg. loss: 1.725129\n",
      "Total training time: 27.87 seconds.\n",
      "-- Epoch 33\n",
      "Norm: 107.46, NNZs: 297, Bias: -190.978657, T: 26136132, Avg. loss: 1.675800\n",
      "Total training time: 28.70 seconds.\n",
      "-- Epoch 34\n",
      "Norm: 105.57, NNZs: 297, Bias: -186.700853, T: 26928136, Avg. loss: 1.667897\n",
      "Total training time: 29.53 seconds.\n",
      "-- Epoch 35\n",
      "Norm: 103.84, NNZs: 297, Bias: -182.527711, T: 27720140, Avg. loss: 1.612296\n",
      "Total training time: 30.34 seconds.\n",
      "-- Epoch 36\n",
      "Norm: 102.38, NNZs: 297, Bias: -178.373264, T: 28512144, Avg. loss: 1.563361\n",
      "Total training time: 31.16 seconds.\n",
      "-- Epoch 37\n",
      "Norm: 100.99, NNZs: 297, Bias: -174.350186, T: 29304148, Avg. loss: 1.542000\n",
      "Total training time: 31.98 seconds.\n",
      "-- Epoch 38\n",
      "Norm: 99.42, NNZs: 297, Bias: -170.592582, T: 30096152, Avg. loss: 1.506768\n",
      "Total training time: 32.81 seconds.\n",
      "-- Epoch 39\n",
      "Norm: 97.99, NNZs: 297, Bias: -166.887362, T: 30888156, Avg. loss: 1.480886\n",
      "Total training time: 33.65 seconds.\n",
      "-- Epoch 40\n",
      "Norm: 96.36, NNZs: 297, Bias: -163.434958, T: 31680160, Avg. loss: 1.455000\n",
      "Total training time: 34.54 seconds.\n",
      "-- Epoch 41\n",
      "Norm: 95.06, NNZs: 297, Bias: -159.932869, T: 32472164, Avg. loss: 1.421530\n",
      "Total training time: 35.45 seconds.\n",
      "-- Epoch 42\n",
      "Norm: 93.76, NNZs: 297, Bias: -156.551189, T: 33264168, Avg. loss: 1.385579\n",
      "Total training time: 36.30 seconds.\n",
      "-- Epoch 43\n",
      "Norm: 92.54, NNZs: 297, Bias: -153.246156, T: 34056172, Avg. loss: 1.351133\n",
      "Total training time: 37.10 seconds.\n",
      "-- Epoch 44\n",
      "Norm: 91.32, NNZs: 297, Bias: -150.060458, T: 34848176, Avg. loss: 1.324937\n",
      "Total training time: 37.94 seconds.\n",
      "-- Epoch 45\n",
      "Norm: 89.97, NNZs: 297, Bias: -147.057546, T: 35640180, Avg. loss: 1.307352\n",
      "Total training time: 38.79 seconds.\n",
      "-- Epoch 46\n",
      "Norm: 88.64, NNZs: 297, Bias: -144.143653, T: 36432184, Avg. loss: 1.268660\n",
      "Total training time: 39.63 seconds.\n",
      "-- Epoch 47\n",
      "Norm: 87.49, NNZs: 297, Bias: -141.219343, T: 37224188, Avg. loss: 1.244363\n",
      "Total training time: 40.45 seconds.\n",
      "-- Epoch 48\n",
      "Norm: 86.47, NNZs: 297, Bias: -138.311302, T: 38016192, Avg. loss: 1.215180\n",
      "Total training time: 41.25 seconds.\n",
      "-- Epoch 49\n",
      "Norm: 85.36, NNZs: 297, Bias: -135.549209, T: 38808196, Avg. loss: 1.204529\n",
      "Total training time: 42.06 seconds.\n",
      "-- Epoch 50\n",
      "Norm: 84.23, NNZs: 297, Bias: -132.889245, T: 39600200, Avg. loss: 1.180018\n",
      "Total training time: 42.86 seconds.\n",
      "-- Epoch 51\n",
      "Norm: 82.99, NNZs: 297, Bias: -130.378034, T: 40392204, Avg. loss: 1.160943\n",
      "Total training time: 43.72 seconds.\n",
      "-- Epoch 52\n",
      "Norm: 81.94, NNZs: 297, Bias: -127.829510, T: 41184208, Avg. loss: 1.126029\n",
      "Total training time: 44.54 seconds.\n",
      "-- Epoch 53\n",
      "Norm: 80.95, NNZs: 297, Bias: -125.326326, T: 41976212, Avg. loss: 1.096659\n",
      "Total training time: 45.38 seconds.\n",
      "-- Epoch 54\n",
      "Norm: 79.93, NNZs: 297, Bias: -122.911020, T: 42768216, Avg. loss: 1.093960\n",
      "Total training time: 46.19 seconds.\n",
      "-- Epoch 55\n",
      "Norm: 79.02, NNZs: 297, Bias: -120.495499, T: 43560220, Avg. loss: 1.061303\n",
      "Total training time: 47.03 seconds.\n",
      "-- Epoch 56\n",
      "Norm: 77.89, NNZs: 297, Bias: -118.296176, T: 44352224, Avg. loss: 1.044807\n",
      "Total training time: 47.84 seconds.\n",
      "-- Epoch 57\n",
      "Norm: 77.01, NNZs: 297, Bias: -116.008991, T: 45144228, Avg. loss: 1.020237\n",
      "Total training time: 48.66 seconds.\n",
      "-- Epoch 58\n",
      "Norm: 76.08, NNZs: 297, Bias: -113.813933, T: 45936232, Avg. loss: 1.004243\n",
      "Total training time: 49.47 seconds.\n",
      "-- Epoch 59\n",
      "Norm: 75.22, NNZs: 297, Bias: -111.625732, T: 46728236, Avg. loss: 0.983207\n",
      "Total training time: 50.28 seconds.\n",
      "-- Epoch 60\n",
      "Norm: 74.36, NNZs: 297, Bias: -109.508631, T: 47520240, Avg. loss: 0.971357\n",
      "Total training time: 51.09 seconds.\n",
      "-- Epoch 61\n",
      "Norm: 73.50, NNZs: 297, Bias: -107.434694, T: 48312244, Avg. loss: 0.954760\n",
      "Total training time: 51.90 seconds.\n",
      "-- Epoch 62\n",
      "Norm: 72.54, NNZs: 297, Bias: -105.486158, T: 49104248, Avg. loss: 0.947773\n",
      "Total training time: 52.75 seconds.\n",
      "-- Epoch 63\n",
      "Norm: 71.76, NNZs: 297, Bias: -103.475401, T: 49896252, Avg. loss: 0.918122\n",
      "Total training time: 53.55 seconds.\n",
      "-- Epoch 64\n",
      "Norm: 70.89, NNZs: 297, Bias: -101.570366, T: 50688256, Avg. loss: 0.903833\n",
      "Total training time: 54.38 seconds.\n",
      "-- Epoch 65\n",
      "Norm: 70.20, NNZs: 297, Bias: -99.599184, T: 51480260, Avg. loss: 0.876035\n",
      "Total training time: 55.22 seconds.\n",
      "-- Epoch 66\n",
      "Norm: 69.33, NNZs: 297, Bias: -97.800601, T: 52272264, Avg. loss: 0.876393\n",
      "Total training time: 56.08 seconds.\n",
      "-- Epoch 67\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Norm: 68.59, NNZs: 297, Bias: -95.956787, T: 53064268, Avg. loss: 0.847517\n",
      "Total training time: 56.89 seconds.\n",
      "-- Epoch 68\n",
      "Norm: 67.81, NNZs: 297, Bias: -94.185878, T: 53856272, Avg. loss: 0.843900\n",
      "Total training time: 57.70 seconds.\n",
      "-- Epoch 69\n",
      "Norm: 67.17, NNZs: 297, Bias: -92.363160, T: 54648276, Avg. loss: 0.814352\n",
      "Total training time: 58.50 seconds.\n",
      "-- Epoch 70\n",
      "Norm: 66.33, NNZs: 297, Bias: -90.730191, T: 55440280, Avg. loss: 0.823622\n",
      "Total training time: 59.41 seconds.\n",
      "-- Epoch 71\n",
      "Norm: 65.56, NNZs: 297, Bias: -89.079199, T: 56232284, Avg. loss: 0.793052\n",
      "Total training time: 60.23 seconds.\n",
      "-- Epoch 72\n",
      "Norm: 64.74, NNZs: 297, Bias: -87.516689, T: 57024288, Avg. loss: 0.776150\n",
      "Total training time: 61.14 seconds.\n",
      "-- Epoch 73\n",
      "Norm: 64.09, NNZs: 297, Bias: -85.872145, T: 57816292, Avg. loss: 0.774081\n",
      "Total training time: 61.94 seconds.\n",
      "-- Epoch 74\n",
      "Norm: 63.42, NNZs: 297, Bias: -84.277051, T: 58608296, Avg. loss: 0.755833\n",
      "Total training time: 62.73 seconds.\n",
      "-- Epoch 75\n",
      "Norm: 62.65, NNZs: 297, Bias: -82.790984, T: 59400300, Avg. loss: 0.749963\n",
      "Total training time: 63.53 seconds.\n",
      "-- Epoch 76\n",
      "Norm: 62.02, NNZs: 297, Bias: -81.237160, T: 60192304, Avg. loss: 0.729039\n",
      "Total training time: 64.32 seconds.\n",
      "-- Epoch 77\n",
      "Norm: 61.43, NNZs: 297, Bias: -79.697288, T: 60984308, Avg. loss: 0.713731\n",
      "Total training time: 65.12 seconds.\n",
      "-- Epoch 78\n",
      "Norm: 60.73, NNZs: 297, Bias: -78.273542, T: 61776312, Avg. loss: 0.712217\n",
      "Total training time: 65.91 seconds.\n",
      "-- Epoch 79\n",
      "Norm: 60.06, NNZs: 297, Bias: -76.849398, T: 62568316, Avg. loss: 0.694422\n",
      "Total training time: 66.71 seconds.\n",
      "-- Epoch 80\n",
      "Norm: 59.38, NNZs: 297, Bias: -75.481367, T: 63360320, Avg. loss: 0.687049\n",
      "Total training time: 67.51 seconds.\n",
      "-- Epoch 81\n",
      "Norm: 58.69, NNZs: 297, Bias: -74.158106, T: 64152324, Avg. loss: 0.675729\n",
      "Total training time: 68.30 seconds.\n",
      "-- Epoch 82\n",
      "Norm: 58.08, NNZs: 297, Bias: -72.792378, T: 64944328, Avg. loss: 0.657054\n",
      "Total training time: 69.09 seconds.\n",
      "-- Epoch 83\n",
      "Norm: 57.49, NNZs: 297, Bias: -71.452931, T: 65736332, Avg. loss: 0.654375\n",
      "Total training time: 69.89 seconds.\n",
      "-- Epoch 84\n",
      "Norm: 56.88, NNZs: 297, Bias: -70.152719, T: 66528336, Avg. loss: 0.640333\n",
      "Total training time: 70.68 seconds.\n",
      "-- Epoch 85\n",
      "Norm: 56.25, NNZs: 297, Bias: -68.901669, T: 67320340, Avg. loss: 0.634907\n",
      "Total training time: 71.48 seconds.\n",
      "-- Epoch 86\n",
      "Norm: 55.64, NNZs: 297, Bias: -67.663381, T: 68112344, Avg. loss: 0.625953\n",
      "Total training time: 72.27 seconds.\n",
      "-- Epoch 87\n",
      "Norm: 55.05, NNZs: 297, Bias: -66.442070, T: 68904348, Avg. loss: 0.614453\n",
      "Total training time: 73.06 seconds.\n",
      "-- Epoch 88\n",
      "Norm: 54.50, NNZs: 297, Bias: -65.207009, T: 69696352, Avg. loss: 0.604010\n",
      "Total training time: 73.86 seconds.\n",
      "-- Epoch 89\n",
      "Norm: 53.85, NNZs: 297, Bias: -64.080759, T: 70488356, Avg. loss: 0.605976\n",
      "Total training time: 74.65 seconds.\n",
      "-- Epoch 90\n",
      "Norm: 53.34, NNZs: 297, Bias: -62.875318, T: 71280360, Avg. loss: 0.583694\n",
      "Total training time: 75.45 seconds.\n",
      "-- Epoch 91\n",
      "Norm: 52.75, NNZs: 297, Bias: -61.758282, T: 72072364, Avg. loss: 0.581532\n",
      "Total training time: 76.25 seconds.\n",
      "-- Epoch 92\n",
      "Norm: 52.18, NNZs: 297, Bias: -60.647652, T: 72864368, Avg. loss: 0.570003\n",
      "Total training time: 77.04 seconds.\n",
      "-- Epoch 93\n",
      "Norm: 51.64, NNZs: 297, Bias: -59.543630, T: 73656372, Avg. loss: 0.556499\n",
      "Total training time: 77.84 seconds.\n",
      "-- Epoch 94\n",
      "Norm: 51.00, NNZs: 297, Bias: -58.540537, T: 74448376, Avg. loss: 0.552829\n",
      "Total training time: 78.63 seconds.\n",
      "-- Epoch 95\n",
      "Norm: 50.51, NNZs: 297, Bias: -57.446406, T: 75240380, Avg. loss: 0.542411\n",
      "Total training time: 79.42 seconds.\n",
      "-- Epoch 96\n",
      "Norm: 50.02, NNZs: 297, Bias: -56.362047, T: 76032384, Avg. loss: 0.538305\n",
      "Total training time: 80.22 seconds.\n",
      "-- Epoch 97\n",
      "Norm: 49.48, NNZs: 297, Bias: -55.356506, T: 76824388, Avg. loss: 0.526352\n",
      "Total training time: 81.01 seconds.\n",
      "-- Epoch 98\n",
      "Norm: 48.98, NNZs: 297, Bias: -54.337350, T: 77616392, Avg. loss: 0.520875\n",
      "Total training time: 81.80 seconds.\n",
      "-- Epoch 99\n",
      "Norm: 48.45, NNZs: 297, Bias: -53.363496, T: 78408396, Avg. loss: 0.514484\n",
      "Total training time: 82.60 seconds.\n",
      "-- Epoch 100\n",
      "Norm: 47.93, NNZs: 297, Bias: -52.398489, T: 79200400, Avg. loss: 0.503714\n",
      "Total training time: 83.39 seconds.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "SGDClassifier(alpha=0.0001, average=False, class_weight='balanced',\n",
       "       epsilon=0.1, eta0=0.0, fit_intercept=True, l1_ratio=0.15,\n",
       "       learning_rate='optimal', loss='log', max_iter=100, n_iter=None,\n",
       "       n_jobs=1, penalty='l2', power_t=0.5, random_state=None,\n",
       "       shuffle=True, tol=None, verbose=True, warm_start=False)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# train model\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "clf = SGDClassifier(loss='log',class_weight='balanced',max_iter=100,verbose=True) # sgd classifier\n",
    "clf.fit(x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.919460409491\n"
     ]
    }
   ],
   "source": [
    "# accuracy_test\n",
    "from sklearn import metrics\n",
    "y_test_predict = clf.predict(x_test)\n",
    "print(metrics.accuracy_score(y_test,y_test_predict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\python352\\lib\\site-packages\\sklearn\\linear_model\\base.py:340: RuntimeWarning: overflow encountered in exp\n",
      "  np.exp(prob, prob)\n"
     ]
    }
   ],
   "source": [
    "# probability output for future evaluation\n",
    "y_test_predict = clf.predict_proba(x_test)\n",
    "result = pd.DataFrame({'score':y_test_predict[:,1],'truth':y_test})\n",
    "result.to_csv('./result/large_wb_sgd_notime.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['wb_sgd.pkl']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# save model\n",
    "from sklearn.externals import joblib\n",
    "model_name = 'wb_sgd.pkl'\n",
    "joblib.dump(clf,model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
